{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Geoffroy Dufay, Louis Lapassat : diabete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### loading libraries ###\n",
    "#########################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "##############################\n",
    "### fixing some parameters ###\n",
    "##############################\n",
    "\n",
    "sns.set(style=\"darkgrid\", palette=\"muted\", font_scale=1.5)\n",
    "random_seed = 141421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabete = datasets.load_diabetes()\n",
    "df = pd.DataFrame(data=diabete.data, columns=diabete.feature_names)\n",
    "df['target'] = diabete.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline. \n",
    "\n",
    "**Note**: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1). For instance if `f` is a feature we have:\n",
    "\n",
    "$$ \\frac{f - mean(f)}{std(f)} \\times n\\_samples$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune_Plot function that will test all our models\n",
    "\n",
    "It uses a conbination of grid search CV to optimize on a set of parameters. Type `help(tune_plot)` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def tune_plot(model, param, X, y, normalize=1, iter_gridsearch=1, nb_cv=5, test_size=0.3, seed=141421):\n",
    "    \n",
    "    \"\"\"\n",
    "    Tune a given model with GridSearchCV and give for accuracy results with a confusion matrix.\n",
    "    \n",
    "    First you need to make sure that you imported the library for your model!\n",
    "    \n",
    "    model = classificator\n",
    "    param = parameters of your classificator that you want to tune \n",
    "    X = data for prediction (DataFrame pref)\n",
    "    y = target to predict (DataFrame pref)\n",
    "    normalize = True/False (normalize both X and y with StandardScaler and LabelEncoder)\n",
    "    iter_gridsearch = number of iteration for GridSearchCV (can be usefull if your model involve randomness)\n",
    "    nb_cv = number of cross validation\n",
    "    test_size = test size in percent (splitting train and test set)\n",
    "    seed = seed for random state\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\" ************************* \", str(model), \" ************************* \")\n",
    "    \n",
    "    ######################\n",
    "    ### Normalize data ###\n",
    "    ######################\n",
    "    \n",
    "    if normalize:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(y)\n",
    "        yy = le.transform(y)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        XX = scaler.transform(X)\n",
    "    else:\n",
    "        yy = y\n",
    "        XX = X\n",
    "    \n",
    "    ####################\n",
    "    ### GridSearchCV ###\n",
    "    ####################\n",
    "    \n",
    "    if iter_gridsearch > 1:\n",
    "        keys = param.keys()\n",
    "        dic_result = {key: [] for key in keys}\n",
    "        for i in tqdm(range(iter_gridsearch)):\n",
    "            clf = model()\n",
    "            result_grid_search = GridSearchCV(estimator=clf, param_grid=param, cv=nb_cv, return_train_score=False)\n",
    "            result_grid_search.fit(XX, yy)\n",
    "            for key in keys:\n",
    "                dic_result[key].append(result_grid_search.best_params_[key])\n",
    "        best_param = {}\n",
    "        for key in keys:\n",
    "            track = {}\n",
    "            for item in dic_result[key]: \n",
    "                if item not in track:\n",
    "                    track[item] = 0\n",
    "                else:\n",
    "                    track[item] += 1\n",
    "            best_param[key] = max(track, key=track.get)\n",
    "    else:\n",
    "        clf = model()\n",
    "        result_grid_search = GridSearchCV(estimator=clf, param_grid=param, cv=nb_cv)\n",
    "        result_grid_search.fit(XX, yy)\n",
    "        best_param = result_grid_search.best_params_\n",
    "    \n",
    "    print('best parameters: ', best_param)\n",
    "    \n",
    "    ####################\n",
    "    ### update model ###\n",
    "    ####################\n",
    "    \n",
    "    clf = model(**best_param)\n",
    "    \n",
    "    ########################\n",
    "    ### train / test set ###\n",
    "    ########################\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(XX, yy, test_size=test_size, random_state=seed)\n",
    "    \n",
    "    #################\n",
    "    ### fit model ###\n",
    "    #################    \n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    #############\n",
    "    ### Score ###\n",
    "    #############\n",
    "    \n",
    "    print(\"Mean squared error (on test set): %.2f\" % mean_squared_error(y_test, clf.predict(x_test)))\n",
    "    print('Variance score (max_value=1 for perfect prediction): %.2f' % r2_score(y_test, clf.predict(x_test)))\n",
    "    \n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of the MLPRegressor with GridSearhCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *************************  <class 'sklearn.neural_network.multilayer_perceptron.MLPRegressor'>  ************************* \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e76e1609bf4c658d8107604550f694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best parameters:  {'hidden_layer_sizes': (150,), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.1}\n",
      "Mean squared error (on test set): 1790.67\n",
      "Variance score (max_value=1 for perfect prediction): 0.45\n"
     ]
    }
   ],
   "source": [
    "param = { \n",
    "    'hidden_layer_sizes' : [(50,), (100,), (150,)], # (100,) is default\n",
    "    'activation' : ['relu', 'logistic', 'tanh', 'identity'], # 'relu' is default\n",
    "    'solver' : ['lbfgs', 'adam', 'sgd'], # 'adam' is default\n",
    "    'alpha' : [0.01, 0.1] # 0.0001 is default\n",
    "    }\n",
    "\n",
    "best_param_MLP = tune_plot(MLPRegressor, param,\n",
    "                          df.drop(['target'], axis=1), df['target'], normalize=True,\n",
    "                          iter_gridsearch=5, nb_cv=3, test_size=0.3, seed=141421)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of the SVR with GridSearhCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *************************  <class 'sklearn.svm.classes.SVR'>  ************************* \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0c41eeb89e41e49e4ee290c202ef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best parameters:  {'kernel': 'sigmoid', 'gamma': 1}\n",
      "Mean squared error (on test set): 1989.00\n",
      "Variance score (max_value=1 for perfect prediction): 0.39\n"
     ]
    }
   ],
   "source": [
    "param = { \n",
    "    'kernel' : ['rbf', 'sigmoid'], # rbf is default\n",
    "    'gamma' : [0.01, 0.1, 1, 10] # auto is default\n",
    "    }\n",
    "\n",
    "best_param_MLP = tune_plot(SVR, param,\n",
    "                          df.drop(['target'], axis=1), df['target'], normalize=True,\n",
    "                          iter_gridsearch=10, nb_cv=3, test_size=0.3, seed=141421)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import backend as K\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "K.clear_session()\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='sigmoid', input_dim=10, kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "    model.add(Dense(75, activation='elu', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "    model.add(Dense(50, activation='softplus', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "    model.add(Dense(1, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Compile model\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=50, batch_size=4, verbose=0)\n",
    "\n",
    "#kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "#results = cross_val_score(estimator, X.drop('hierarchy', axis=1), dummy_y, cv=kfold)\n",
    "#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# Fit the model\n",
    "#model.fit(x_train, y_train, epochs=20, batch_size=20, verbose=1, use_multiprocessing=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "# Fit the model\n",
    "history = estimator.fit(X.drop('type', axis=1),  keras.utils.to_categorical(encoded_Y), validation_split=0.33, epochs=500, batch_size=5, verbose=0)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, = plt.plot(range(len( history.history['loss'])), history.history['loss'], label=\"loss\")\n",
    "acc, = plt.plot(range(len( history.history['loss'])), history.history['acc'], label=\"acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
